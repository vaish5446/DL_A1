{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Random Search): {'epochs': 500, 'learning_rate': 0.3864165025399161, 'regularization': 0.025966252220214196}\n",
      "Test Accuracy (Random Search): 0.7337662337662337\n",
      "Classification Report (Random Search):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.40      0.52        55\n",
      "           1       0.73      0.92      0.82        99\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.73      0.66      0.67       154\n",
      "weighted avg       0.73      0.73      0.71       154\n",
      "\n",
      "Confusion Matrix (Random Search):\n",
      " [[22 33]\n",
      " [ 8 91]]\n",
      "Training data shape: X_train_pre = (614, 9), y_train_pre = (614,)\n",
      "Test data shape: X_test_pre = (154, 9), y_test_pre = (154,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split \n",
    "from scipy.stats import uniform\n",
    "\n",
    "class EnhancedPerceptron(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, regularization=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.regularization = regularization\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis=1)  \n",
    "        self.weights = np.zeros(X.shape[1])  \n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                net_input = np.dot(X[i], self.weights)\n",
    "                output = self.sigmoid(net_input)\n",
    "                error = y[i] - output\n",
    "\n",
    "                \n",
    "                regularization_term = self.regularization * self.weights\n",
    "                self.weights += self.learning_rate * error * X[i] - regularization_term\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.insert(X, 0, 1, axis=1)  \n",
    "        net_input = np.dot(X, self.weights)\n",
    "        output = self.sigmoid(net_input)\n",
    "        return (output >= 0.5).astype(int)  \n",
    "\n",
    "def load_preprocessed_txt(file_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  \n",
    "            parts = line.split()  \n",
    "            \n",
    "            label = int(parts[0])\n",
    "            labels.append(1 if label == 1 else 0)  \n",
    "            \n",
    "            feature_vector = np.zeros(9)  \n",
    "            \n",
    "            for feature in parts[1:]:\n",
    "                index, value = feature.split(':')\n",
    "                index = int(index) - 1  \n",
    "                feature_vector[index] = float(value)  \n",
    "            \n",
    "            data.append(feature_vector)  \n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "file_path = r'F:\\AUSTRALIA\\EDU\\UOA\\TRI 4\\DLF\\A1\\data\\diabetes_scale.txt'\n",
    "X_preprocessed, y_preprocessed = load_preprocessed_txt(file_path)\n",
    "\n",
    "X_train_pre, X_test_pre, y_train_pre, y_test_pre = train_test_split(X_preprocessed, y_preprocessed, test_size=0.2, random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'learning_rate': uniform(0.001, 1.0),  \n",
    "    'epochs': [100, 500, 1000, 2000],\n",
    "    'regularization': uniform(0.01, 1.0)  \n",
    "}\n",
    "\n",
    "\n",
    "perceptron = EnhancedPerceptron()\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=perceptron,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  \n",
    "    cv=5,  \n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_pre, y_train_pre)\n",
    "\n",
    "print(\"Best Hyperparameters (Random Search):\", random_search.best_params_)\n",
    "\n",
    "best_random_model = random_search.best_estimator_\n",
    "y_pred_best_random = best_random_model.predict(X_test_pre)\n",
    "\n",
    "print(\"Test Accuracy (Random Search):\", accuracy_score(y_test_pre, y_pred_best_random))\n",
    "print(\"Classification Report (Random Search):\\n\", classification_report(y_test_pre, y_pred_best_random))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_pre, y_pred_best_random)\n",
    "print(\"Confusion Matrix (Random Search):\\n\", conf_matrix)\n",
    "\n",
    "print(f\"Training data shape: X_train_pre = {X_train_pre.shape}, y_train_pre = {y_train_pre.shape}\")\n",
    "print(f\"Test data shape: X_test_pre = {X_test_pre.shape}, y_test_pre = {y_test_pre.shape}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
